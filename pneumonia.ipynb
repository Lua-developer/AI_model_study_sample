{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, Model\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로 설정\n",
    "BASE_PATH = 'chest_xray'\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, 'train')\n",
    "TEST_PATH = os.path.join(BASE_PATH, 'test')\n",
    "VAL_PATH = os.path.join(BASE_PATH, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineModelArchitecture(_img_dims) :\n",
    "    #input layers\n",
    "    inputs = layers.Input(shape=(_img_dims, _img_dims, 3))\n",
    "    # first Conv Block\n",
    "    x = layers.Conv2D(16, (3,3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    # Second Conv Block\n",
    "    x = layers.SeparableConv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.SeparableConv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    # Third Conv Block\n",
    "    x = layers.SeparableConv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.SeparableConv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Dropout(rate=0.2)(x)\n",
    "    # Fifth Cov Block\n",
    "    x = layers.SeparableConv2D(256, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.SeparableConv2D(256, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Dropout(rate=0.2)(x)\n",
    "    \n",
    "    # Fully Connected Net\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(rate=0.7)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(rate=0.5)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(rate=0.3)(x)\n",
    "    \n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    return inputs, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# 훈련 이미지 전처리\n",
    "train_image_gen = ImageDataGenerator(rescale = 1./255,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True)\n",
    "# 테스트에 사용되는 이미지는 정규화만 적용한다.\n",
    "test_image_gen = ImageDataGenerator(rescale=1./255)\n",
    "# 훈련용 이미지를 폴더에서 가져온다.\n",
    "train_set = train_image_gen.flow_from_directory('chest_xray/train/',\n",
    "                                                target_size=(150,150),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')\n",
    "# 테스트용 이미지를 폴더에서 가져온다.\n",
    "test_set = test_image_gen.flow_from_directory('chest_xray/test/',\n",
    "                                              target_size=(150,150),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_dims = 150\n",
    "inputs, output = defineModelArchitecture(img_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 150, 150, 16)      448       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 150, 150, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 75, 75, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " separable_conv2d_6 (Separab  (None, 75, 75, 32)       688       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " separable_conv2d_7 (Separab  (None, 75, 75, 32)       1344      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 75, 75, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 37, 37, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " separable_conv2d_8 (Separab  (None, 37, 37, 64)       2400      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " separable_conv2d_9 (Separab  (None, 37, 37, 64)       4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 37, 37, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 18, 18, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 18, 18, 64)        0         \n",
      "                                                                 \n",
      " separable_conv2d_10 (Separa  (None, 18, 18, 256)      17216     \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " separable_conv2d_11 (Separa  (None, 18, 18, 256)      68096     \n",
      " bleConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 18, 18, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 9, 9, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 9, 9, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 20736)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               10617344  \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,789,985\n",
      "Trainable params: 10,789,281\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUA\\AppData\\Local\\Temp\\ipykernel_20148\\4285692120.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "139/300 [============>.................] - ETA: 2:42 - loss: 0.3303 - acc: 0.8451"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "model.fit_generator(train_set,\n",
    "                    steps_per_epoch=300,\n",
    "                    epochs=25,\n",
    "                    validation_data= test_set,\n",
    "                    validation_steps=2000)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "331259889d6aea7cac7f8fa3ac8b4b857d2930e7f5bcfc9b82cc526690fa0cde"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
